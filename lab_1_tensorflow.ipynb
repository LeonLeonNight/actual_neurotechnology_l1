{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая реализация метода обратного распространения ошибки \n",
    "для двухслойной полностью связанной нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое MNIST и как его загружать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных MNIST\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Преобразование входных изображений в одномерный массив и нормализация пикселей\n",
    "x_train = x_train.reshape(-1, 784) / 255.0 \n",
    "x_test = x_test.reshape(-1, 784) / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем архитектуру модели\n",
    "\n",
    "С помощью инструментов keras.Sequential определяем последовательную модель нейронной сети, который добавляет два полностью связанных слоя, каждый с определенным числом нейронов.\n",
    "\n",
    "Первый слой использует функцию активации sigmoid и принимает входные данные в форме вектора размерности 784 (28 на 28).\n",
    "\n",
    "Второй слой обычно используется в задачах классификации и использует функцию активации softmax, чтобы вычислить вероятности принадлежности объектов к тому или иному классу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Определение архитектуры модели\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='sigmoid', input_shape=(784,)),\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели на тренировочных данных\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Оценка модели на тестовых данных\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Расчет градиента потерь по отношению к весам модели в выходных слоях\n",
    "with tf.GradientTape() as tape:\n",
    "    logits = model(x_train, training=False)\n",
    "    loss_value = keras.backend.sparse_categorical_crossentropy(y_train, logits)\n",
    "\n",
    "grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "# Обновление весов модели на основе градиентов\n",
    "model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "# Повторное обучение модели с обновленными весами\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
